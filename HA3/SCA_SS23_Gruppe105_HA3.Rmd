---
title: "Gruppe 105 Hausaufgabe 3"
subtitle: "Supply Chain Analytics SS23"
author: "Cordelia Mena Hernandez, Daniel Glatter"
date: "2023-06-07"
output: pdf_document
header-includes:
  \usepackage{fvextra}
  \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
---

```{r setup, include=FALSE}
# Laden von Packages
library(tidyverse)
library(lubridate)
library(forecast)
library(zoo)
library(scales)
library(ggplot2)
library(knitr)
library(GGally)
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE, echo = TRUE, warning = FALSE, message = FALSE)
```

# Daten für die Modellierung vorbereiten

## Aufgabe 1
```{r}
# Laden der Daten in die Dataframes 'services' und 'externals'
externals <- read.csv("externals20.csv", sep=";", dec=",")
services <- read.csv("../HA1/data/output_services_8Players_v0020.csv", sep=";", dec=",")

# Tabelle Externals aufbereiten
# Characters in Factors umwandeln
externals$region <- as.factor(externals$region)

# Periode anpassen
externals$Period <- as.yearmon(make_date(year=externals$Year, month = externals$Month))
externals <-subset(externals, select=-c(Year, Month))

# Tabelle Services aufbereiten
# Umwandlung ins Datumsformat
services$Date <- make_date(services$Year, services$Month, services$Day)
services <- subset(services, select=-c(Year, Month, Day))

# Characters in Factors umwandeln
services$region = as.factor(services$region)
services$storename = as.factor(services$storename)
services$Product = as.factor(services$Product)
services$vendor = as.factor(services$vendor)
services$service = as.factor(services$service)

# Periode hinzufügen
services$Period <- as.yearmon(services$Date)

# OTD, IFR berechnen
services$IFR <- services$QExecuted / services$QScheduled
services$OTD <- services$DaysExecuted <= services$DaysScheduled  # true/false

# LDL nach OTD aggregieren
ldl_otd <- services %>%
  group_by(Logistikdienstleister=vendor, service) %>%
  summarize(OTD = mean(OTD)) %>%
  arrange(OTD)

ldl_otd %>% kable(caption="Logistikdienstleister nach On-Time Delivery Rate", digits=3)
```

```{r}
# Tabelle nach IFR aggregieren
ldl_ifr <- services %>%
  group_by(Logistikdienstleister=vendor, service) %>%
  summarize(IFR = mean(IFR)) %>%
  arrange(IFR)

ldl_ifr %>% kable(caption="Logistikdienstleister nach In-Full Rate", digits=3)
```


## Aufgabe 2

```{r}
# Daten nach Monat zusammenfassen
ldl_ifr_warehousing <- services %>%
  filter(service == "Warehousing") %>%
  group_by(Logistikdienstleister=vendor, region, Period) %>%
  summarize(IFR = mean(IFR)) %>%
  arrange(IFR)

ldl_ifr_warehousing %>% kable(caption='In-Full Rate der Warehousing-LDL nach Region und Periode', digits=3)
```

```{r}
# Insgesamt bester Warehousing-LDL
ldl_ifr_warehousing %>%
  group_by(Logistikdienstleister) %>%
  summarize(IFR=mean(IFR)) %>%
  arrange(desc(IFR)) %>%
  head(1) %>%
  kable(caption="Bester LDL nach IFR, über Regionen und Perioden hinweg", digits=3)
```

Der insgesamt beste LDL über alle Regionen und Perioden hinweg ist Flying Mercury Warehousing mit einer IFR von 83,7%.

```{r}
# Schlechtester IFR‐Wert (und Periode) dieses LDL
ldl_ifr_warehousing %>%
  filter(Logistikdienstleister == "Flying Mercury Warehousing") %>%
  filter(region == "Shangh") %>%
  arrange(IFR) %>%
  head(1) %>%
  kable(caption="Schlechtester IFR-Wert und Periode von Flying Mercury Warehousing in der Region Shanghai", digits=3)
```

Der schlechteste IFR-Wert von Flying Mercury Warehousing in der Region Shanghai beträgt 78,4% und war im Mai 2022.

## Aufgabe 3

```{r}
# Daten nach Monat zusammenfassen
ldl_ifr_shipping <- services %>%
  filter(service == "Shipping") %>%
  group_by(Logistikdienstleister=vendor, region, Period=Period) %>%
  summarize(OTD = mean(OTD)) %>%
  # Sortieren nach OTD Rate
  arrange(OTD)

ldl_ifr_shipping %>% kable(caption='On-Time Delivery Rate der Shipping-LDL nach Region und Periode', digits=3)
```

```{r}
# Schlechtester OTD‐Wert in Japan im April 2019
ldl_ifr_shipping %>%
  filter(Period == "Apr 2019") %>%
  filter(region == "Japan") %>%
  arrange(OTD) %>%
  head(1) %>%
  kable(caption="Aufsteigend sortierte OTD-Werte von LDL in der Region Japan im April 2019", digits=3)
```

Der schlechteste OTD-Wert eines Shipping-LDL in der Region Japan im April 2019 beträgt 7.1%. Betroffen ist der Dienstleister CPS Shipping.


# Modellierung: Warehousing

## Aufgabe 4

```{r}
cps_warehousing <- merge(subset(ldl_ifr_warehousing, Logistikdienstleister == "CPS Warehousing"),
                             externals,
                             by=c("Period", "region"))

# Index X aus Externals-Teil löschen
cps_warehousing <- subset(cps_warehousing, select=-c(X))

head(cps_warehousing) %>% kable(caption="IFR Rate sowie externe Einflussfaktoren von CPS Warehousing nach Region und Periode")
```

## Aufgabe 5

### a) Externe Effekte und Korrelation zur IFR
```{r}
correlations_IFR <- cor(cps_warehousing$IFR, cps_warehousing[, 4:ncol(cps_warehousing)])

# Besser lesbarer Output und Sortierung nach Stärke der Korrelation
correlations_IFR <- data.frame(IFR=t(correlations_IFR)) %>%
  arrange(desc(abs(IFR)))

# Ausgabe
correlations_IFR %>%
  kable(caption="Korrelation aller Variablen zur In-Full Rate", digits=4)
```

### b) Die 5 am stärksten korrelierenden Effekte und ihre Korrelationen
```{r}
# 5 stärkste Effekte (neben IFR selbst); 'correlations_IFR' ist schon nach Korrelation sortiert
strongest_five_effects <- rownames(head(correlations_IFR, 6))

cor(subset(cps_warehousing, select=strongest_five_effects)) %>%
  kable(caption="IFR und die 5 stärksten Effekte darauf", digits=4)
```

### c) Korrelations-Plot für die 5 stärksten Effekte
```{r}
ggpairs(subset(cps_warehousing, select=strongest_five_effects),
        progress = FALSE,
        lower = list(continuous = wrap("smooth_loess", colour = "steelblue1")))
```

## Aufgabe 6

```{r}
cps_warehousing$Baseline <- mean(cps_warehousing$IFR)

head(cps_warehousing[, c("Period", "region", "IFR", "Baseline")]) %>%
  kable(caption="Tabellenkopf für LDL CPS Warehousing mit Baseline", digits=4)
```

Eine sehr einfache Baseline stellt der Mittelwert der vorherzusagenden Variable (IFR) dar. Dieser ist leicht zu berechnen und liegt per Definition "im Schnitt richtig". Natürlich kann der Mittelwert allerdings keine Nuancen basierend auf den anderen verfügbaren externen Informationen aufgreifen.

## Aufgabe 7

```{r}
ggplot() +
  # Baseline
  geom_line(data=filter(cps_warehousing, year(Period) <= 2022), aes(x=Period, y=Baseline, color="Baseline")) +
  # IFR Japan
  geom_line(data = filter(cps_warehousing, year(Period) <= 2022 & region == "Japan"), aes(x=Period, y=IFR, color="Japan")) +
  # IFR Peking
  geom_line(data = filter(cps_warehousing, year(Period) <= 2022 & region == "Peking"), aes(x=Period, y=IFR, color="Peking")) +
  xlab("Periode") + 
  ylab("IFR") +
  scale_color_manual(name='IFR',
                     breaks=c('Baseline', 'Japan', 'Peking'),
                     values=c('Baseline'='darkgreen', 'Japan'='blue', 'Peking'='red'))

```


## Aufgabe 8

```{r}
# Data Frame 'Evaluation' erstellen
evaluation <- data.frame(Model = "Baseline",
                        MAE = numeric(1),
                        MAPE = numeric(1),
                        Rsquared = numeric(1),
                        Rsquared_adj = numeric(1))

# MAE berechnen
evaluation[evaluation$Model == "Baseline",]$MAE = mean(abs(cps_warehousing$IFR - cps_warehousing$Baseline))

# MAPE berechnen (SMAPE nicht benötigt, weil IFR immer >0)
evaluation[evaluation$Model == "Baseline",]$MAPE = mean(abs((as.numeric(cps_warehousing$IFR - cps_warehousing$Baseline)/as.numeric(cps_warehousing$IFR))*100))

# R² berechnen
evaluation[evaluation$Model == "Baseline",]$Rsquared = NA

# Adjusted R² berechnen
evaluation[evaluation$Model == "Baseline",]$Rsquared_adj = NA

# Tabelle anzeigen
evaluation %>% kable(caption="Bewertung der Baseline nach MAE und MAPE", digits=3)
```

## Aufgabe 9

```{r}
# Seed setzen
set.seed(4141)

# 80% der Daten für Trainingsset samplen
training_sample_indices <- sample(1:nrow(cps_warehousing), nrow(cps_warehousing) * 0.8)

# Trainingsset
training_data <- cps_warehousing[training_sample_indices, ]
head(training_data) %>%
  kable(caption="Trainingsdaten")
```

```{r}
# Testset
test_data <- cps_warehousing[-training_sample_indices, ]
head(test_data) %>%
  kable(caption="Testdaten")
```
## Aufgabe 10
### Iteration 1: Univariate Modelle
```{r}
# Modelle erstellen
model1 = lm(IFR ~ SkilledLaborAvailability, data = training_data)
model2 = lm(IFR ~ UnskilledLaborAvailability, data = training_data)
model3 = lm(IFR ~ Criminality, data = training_data)
model4 = lm(IFR ~ Inflation, data = training_data)
model5 = lm(IFR ~ AirPollution, data = training_data)

# Zusammenfassung ausgeben zur Betrachtung der statistischen Signifikanz
cat("\nModell 1 -----------------------------------------------------------")
summary(model1)
cat("\nModell 2 -----------------------------------------------------------")
summary(model2)
cat("\nModell 3 -----------------------------------------------------------")
summary(model3)
cat("\nModell 4 -----------------------------------------------------------")
summary(model4)
cat("\nModell 5 -----------------------------------------------------------")
summary(model5)
```

```{r}
# Berechnung der Fehlerkennzahlen und einfügen in DataFrame
# Data Frame erweitern
evaluation = rbind(evaluation, data.frame(Model = c("Model1", "Model2", "Model3", "Model4", "Model5"),
                                          MAE = numeric(5),
                                          MAPE = numeric(5),
                                          Rsquared=numeric(5),
                                          Rsquared_adj=numeric(5)))

# Funktionen definieren für MAE und MAPE
MAE <- function(model) {
  return (mean(abs(model$residuals)))
}

MAPE <- function(model) {
  return (
    mean(abs((as.numeric(model1$residuals)/
                as.numeric(model1$fitted.values + model1$residuals))*100))
  )
}

# MAE berechnen
evaluation[evaluation$Model == "Model1",]$MAE = MAE(model1)
evaluation[evaluation$Model == "Model2",]$MAE = MAE(model1)
evaluation[evaluation$Model == "Model3",]$MAE = MAE(model1)
evaluation[evaluation$Model == "Model4",]$MAE = MAE(model1)
evaluation[evaluation$Model == "Model5",]$MAE = MAE(model1)

# MAPE berechnen (SMAPE nicht benötigt, weil IFR immer >0)
evaluation[evaluation$Model == "Model1",]$MAPE = mean(abs((as.numeric(model1$residuals)/as.numeric(training_data$IFR))*100))
evaluation[evaluation$Model == "Model2",]$MAPE = mean(abs((as.numeric(model2$residuals)/as.numeric(training_data$IFR))*100))
evaluation[evaluation$Model == "Model3",]$MAPE = mean(abs((as.numeric(model3$residuals)/as.numeric(training_data$IFR))*100))
evaluation[evaluation$Model == "Model4",]$MAPE = mean(abs((as.numeric(model4$residuals)/as.numeric(training_data$IFR))*100))
evaluation[evaluation$Model == "Model5",]$MAPE = mean(abs((as.numeric(model5$residuals)/as.numeric(training_data$IFR))*100))

# R² berechnen
evaluation[evaluation$Model == "Model1",]$Rsquared = summary(model1)$r.squared
evaluation[evaluation$Model == "Model2",]$Rsquared = summary(model2)$r.squared
evaluation[evaluation$Model == "Model3",]$Rsquared = summary(model3)$r.squared
evaluation[evaluation$Model == "Model4",]$Rsquared = summary(model4)$r.squared
evaluation[evaluation$Model == "Model5",]$Rsquared = summary(model5)$r.squared

# Adjusted R² berechnen
evaluation[evaluation$Model == "Model1",]$Rsquared_adj = summary(model1)$adj.r.squared
evaluation[evaluation$Model == "Model2",]$Rsquared_adj = summary(model2)$adj.r.squared
evaluation[evaluation$Model == "Model3",]$Rsquared_adj = summary(model3)$adj.r.squared
evaluation[evaluation$Model == "Model4",]$Rsquared_adj = summary(model4)$adj.r.squared
evaluation[evaluation$Model == "Model5",]$Rsquared_adj = summary(model5)$adj.r.squared

# Tabelle anzeigen
evaluation %>% kable(caption="Bewertung der Baseline und der univariaten Modelle nach MAE, MAPE, R² und adjusted R²", digits=3)
```

Wir sehen zunächst, dass alle univariaten Modelle Verbesserungen gegenüber der Baseline darstellen, sowohl nach MAE als auch MAPE.
Wir entscheiden uns hier für Modell 1 (Variable "SkilledLaborAvailability"), da dieses konsistent die besten Werte für MAE, MAPE, R² und Adjusted R² hat. Darüber hinaus sind die Parameter statistisch hoch signifikant (und auch signifikanter als bei den Modellen 3 bis 5 - Modell 2 liegt hier gleich auf).

### Iteration 2: Bivariate Modelle
Um Multikollinearität zu vermeiden, nehmen wir nur Variablen auf, die betragsweise um weniger als 0,75 mit SkilledLaborAvailability korrelieren. Das sind die Variablen "Inflation" und "AirPollution". "UnskilledLaborAvailability" und "Criminality" liegen darüber.

```{r}
# Modelle erstellen
model1_1 = lm(IFR ~ SkilledLaborAvailability + Inflation, data = training_data)
model1_2 = lm(IFR ~ SkilledLaborAvailability + AirPollution, data = training_data)

# Zusammenfassung ausgeben zur Betrachtung der statistischen Signifikanz
cat("\nModell 1.1 -----------------------------------------------------------")
summary(model1_1)
cat("\nModell 1.2 -----------------------------------------------------------")
summary(model1_2)
```

```{r}
# Berechnung der Fehlerkennzahlen und einfügen in DataFrame
# Data Frame erweitern
evaluation = rbind(evaluation, data.frame(Model = c("Model1_1", "Model1_2"),
                                          MAE = numeric(2),
                                          MAPE = numeric(2),
                                          Rsquared=numeric(2),
                                          Rsquared_adj=numeric(2)))

# MAE berechnen
evaluation[evaluation$Model == "Model1_1",]$MAE = MAE(model1_1)
evaluation[evaluation$Model == "Model1_2",]$MAE = MAE(model1_2)

# MAPE berechnen (SMAPE nicht benötigt, weil IFR immer >0)
evaluation[evaluation$Model == "Model1_1",]$MAPE = MAPE(model1_1)
evaluation[evaluation$Model == "Model1_2",]$MAPE = MAPE(model1_2)

# R² berechnen
evaluation[evaluation$Model == "Model1_1",]$Rsquared = summary(model1_1)$r.squared
evaluation[evaluation$Model == "Model1_2",]$Rsquared = summary(model1_2)$r.squared

# Adjusted R² berechnen
evaluation[evaluation$Model == "Model1_1",]$Rsquared_adj = summary(model1_1)$adj.r.squared
evaluation[evaluation$Model == "Model1_2",]$Rsquared_adj = summary(model1_2)$adj.r.squared

# Tabelle anzeigen
evaluation %>% kable(caption="Bewertung aller Modelle (inkl. bivariat) nach MAE, MAPE, R² und adjusted R²", digits=3)
```

Bei Modell1_1 (mit der Variable Inflation) stellen wir keine Verbesserung in den Kennzahlen fest, beim adjusted R² sogar eine Verschlechterung. Darüber hinaus ist der Parameter nicht statistisch signifikant.
Bei Modell1_2 (mit AirPollution) gibt es eine leichte Verbesserung in den Kennzahlen bei immer noch guter statistischer Signifikanz. Die Verbesserung kann die Erhöhung der Modellkomplxität gerade noch rechtfertigen, und wir testen noch ein trivariates Modell.

### Iteration 3: Trivariates Modell
Die Korrelation zwischen AirPollution und Inflation ist sehr gering, daher erstellen wir ein Modell aus den Variablen SkilledLaborAvailability, AirPollution und Inflation (Korrelation mit SkilledLaborAvailability haben wir schon in der zweiten Iteration betrachtet).

```{r}
# Modelle erstellen
model1_2_1 = lm(IFR ~ SkilledLaborAvailability + AirPollution + Inflation, data = training_data)

# Zusammenfassung ausgeben zur Betrachtung der statistischen Signifikanz
cat("\nModell 1.2.1 -----------------------------------------------------------")
summary(model1_2_1)
```

```{r}
# Berechnung der Fehlerkennzahlen und einfügen in DataFrame
# Data Frame erweitern
evaluation = rbind(evaluation, data.frame(Model = c("Model1_2_1"),
                                          MAE = numeric(1),
                                          MAPE = numeric(1),
                                          Rsquared=numeric(1),
                                          Rsquared_adj=numeric(1)))

# MAE berechnen
evaluation[evaluation$Model == "Model1_2_1",]$MAE = MAE(model1_2_1)

# MAPE berechnen (SMAPE nicht benötigt, weil IFR immer >0)
evaluation[evaluation$Model == "Model1_2_1",]$MAPE = MAPE(model1_2_1)

# R² berechnen
evaluation[evaluation$Model == "Model1_2_1",]$Rsquared = summary(model1_2_1)$r.squared

# Adjusted R² berechnen
evaluation[evaluation$Model == "Model1_2_1",]$Rsquared_adj = summary(model1_2_1)$adj.r.squared

# Tabelle anzeigen
evaluation %>% kable(caption="Bewertung aller Modelle (inkl. trivariat) nach MAE, MAPE, R² und adjusted R²", digits=3)
```
Zwar ändern sich im trivariaten Modell MAE und MAPE nicht mehr, aber wir sehen eine Verbesserung von R² und adjusted R². Die Signifikanz der einzelnen Parameter ist immer noch gut bis sehr gut. Wir übernehmen also Modell1_2_1 und beenden hier die Forward Selection, da keine weiteren (unkorrelierten) Variablen mehr zur Verfügung stehen. 

## Aufgabe 11

```{r}
evaluation[evaluation$Model == 'Baseline' | evaluation$Model == 'Model1_2_1', c("MAE", "MAPE")] %>% kable(caption="Vergleich von Baseline zum ausgewählten Modell nach Forward Selection", digits=3)
```
Im Vergleich zur Baseline hat das trivariate Modell einen deutlich geringeren mittleren absoluten Fehler (0,012 vs. 0,018, also 33% weniger) sowie eine geringere prozentuale Abweichung von 1.524% vs. 2.152%.
Für die genaue Vorhersage der In-Full Rate kann allerdings auch eine Abweichung 1,2 Prozentpunkten relevant sein, zumal die Baseline selbst nur 1,8% abweicht.
Insgesamt ist unser Modell also für den vorliegenden Zweck nur mäßig gut. Das sehen wir auch am eher geringen R² (Anteil der erklärten Varianz in den Daten) von 0,513.

## Aufgabe 12
```{r}
# Werte für die Vorhersage zusammenstellen
externals_SH_0423 <- externals[externals$Period=='Apr 2023' &
                                 externals$region=='Shangh',
                                 c("SkilledLaborAvailability", "AirPollution", "Inflation")]
externals_BJ_0423 <- externals[externals$Period=='Apr 2023' &
                                 externals$region=='Peking',
                                 c("SkilledLaborAvailability", "AirPollution", "Inflation")]

# Vorhersage
data.frame(Region=c("Shanghai", "Peking"),
           Periode=c("Apr 2023", "Apr 2023"),
           Vorhersage_IFR=c(predict(model1_2_1, newdata = externals_SH_0423),
                            predict(model1_2_1, newdata = externals_BJ_0423))) %>%
  kable(caption="Vorhersage des IFR-Wertes in Shanghai und Peking im April 2023", digits=4)
```
Nach der Modellvorhersage liegt die In-Full Rate im April 2023 in Shanghai höher als in Peking, die Aussage der Chefin wäre also richtig und wir würden die Wette nicht annehmen.

Der Unterschied beträgt allerdings nur 1,05 Prozentpunkte. Darüber hinaus müssen wir verschiedene Unsicherheitsfaktoren in der Vorhersage berücksichtigen.

Zunächst herrscht Unsicherheit im Modell selbst. Wir könnten beispielsweise Parameter fälschlich aufgenommen haben. Diese Unsicherheit wird durch den p-Wert quantifiziert und ist hier sehr gering. Daneben kann aber auch Multikollinearität zu Unsicherheit in den geschätzten Parametern führen. Sowohl AirPollution (0.50) als auch Inflation (0.68) haben mit SkilledLaborAvailability eine Korrelation, die nicht von der Hand zu weisen ist.

Ein anderes Problem ist, dass relevante Variablen im Modell fehlen könnten. Dies ist nicht unwahrscheinlich, da wir eine eher niedrige erklärte Varianz (R²) haben. Gründe dafür sind beispielsweise dass wir nur die 5 am stärksten mit IFR korrelierten Variablen bei der Forward Selection überhaupt betrachtet haben.
Ggf. müssten hier weitere Variablen betrachtet werden. Auch eine Unterscheidung der Regionen könnte relevant sein, man könnte diese beispielsweise als Dummy-Variable in das Modell mit aufnehmen (derzeit ist das Modell sozusagen der Schnitt über alle Regionen).
Außerdem haben wir kein Feature Engineering betrieben, sodass Variablen ggf. nur geringe Linearität und damit Tauglichkeit für die Regression aufweisen.
Darüber hinaus könnten auch solche Variablen relevant sein, die in unserem Datensatz gänzlich fehlen.

Schließlich kommt eine weitere Unsicherheit aus der Vorhersage der externen Effekte. Wir wissen, dass diese für 2023 auf Vorhersagen beruhen, deren Unsicherheit jedoch unklar ist, da sie aus einer externen Quelle kommen.

In Anbetracht dieser Unsicherheiten, dem ohnehin geringen Abstand der Vorhersage, dem hohen Wetteinsatz und dem Fakt, dass unsere Chefin nach Vorhersage ohnehin Recht hat, würden wir die Wette dankend ablehnen.

# Entscheidung
## Aufgabe 13
Mit dem vorliegenden Modell können wir die In-Full Rate von "CPS Warehousing" basierend auf externen Einflussfaktoren vorhersagen. Entsprechende Modelle könnten wir nun auch für alle weiteren Warehousing-Dienstleister erstellen, oder ein großes Modell für alle Dienstleister (mit den einzelnen WH-DL als Dummy-Variablen).

### Beeinflusste Prozesse
Das Modell kann potenziell unseren gesamten Order-to-Cash-Prozess beeinflussen. Am unmittelbarsten ist natürlich das Warehousing selbst betroffen. Hier können wir mithilfe des Modells wo nötig weitere WH-Dienstleistungen frühzeitig buchen (etwa um übrig gebliebene Flaschen zu packen und laden), proaktiv mit schlecht performenden WH-DL an Verbesserungen arbeiten, oder andere WH-DL auswählen.
Änderungen im Warehousing betreffen auch das Order Management, eine höhere IFR im Warehousing sollte in einer höheren IFR beim Kunden resultieren, womit wir die Kundenzufriedenheit erhöhen und im Idealfall den Auftragseingang und damit den Umsatz steigern können. Neben direkten Verbesserungen kann auch verbesserte Kommunikation die Kundenzufriedenheit steigern, etwa wenn wir Warnungen bspw. bei Extremwetter aussprechen, dass sich voraussichtlich die Ware nicht vollständig liefern lässt.
Auch auf Upstream-Prozesse wie der Produktion oder dem Shipping von der Produktion zu den Großlagern können sich indirekte Auswirkungen ergeben, etwa wenn sich der Ordereingang mittelfristig ändert oder wir sehen, dass Ware an anderen Orten benötigt wird.
Schließlich hat eine bessere Kenntnis der IFR unserer WH-DL auch Einfluss auf die Finanzprozesse, konkret die Debitorenbuchhaltung (Accounts Receivable). Wenn wegen zu niedriger IFR im Lager Ware beim Kunden fehlt, können wir zur Steigerung der Kundenzufriedenheit Rechnungen über unvollständige Lieferungen vorausschauend zurückhalten bzw. Mahnungen unterlassen.

### Nutzer:innen
- Interne Auftraggeber der WH-DL
- Vertrieb (Frühwarnungen, Kundenzufriedenheit)
- Angestellte der Finanzabteilung

### Bereitstellung
- Integration in BI-Dashboards/Reports
- Integration in CRM-Tools
- Integration in ERP-System

### Datenbeschaffung
- ERP-System für Daten zu in Anspruch genommenen Services, um IFR zu berechnen
- Externe Datenbanken für Einflussfaktoren

